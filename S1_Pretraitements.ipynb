{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On importe la librairie pandas et le dataset source et le dataset TEST\n",
    "import pandas as pd\n",
    "df = pd.read_csv('sources/kaggle-give-me-credit-train.csv')\n",
    "df_test = pd.read_csv('sources/kaggle-give-me-credit-test.csv') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Déplace la colonne SeriousDlqin2yrs dans le datatset test pour avoir une organisation des colonnes similaire à cette du dataset TRAIN FULL\n",
    "df_test.drop(['SeriousDlqin2yrs'], axis=1, inplace=True)\n",
    "df_test['SeriousDlqin2yrs'] = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # On décrit le dataset (inutile dans ce cas)\n",
    "# df.describe()\n",
    "# # On liste les lignes 0 à 5 du dataset (inutile dans ce cas)\n",
    "# df[0:5]\n",
    "# # On cherche les colonnes contenant des NaN\n",
    "# df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On supprime les NaN\n",
    "df[['NumberOfDependents']] = df[['NumberOfDependents']].fillna(0)\n",
    "df[['MonthlyIncome']] = df[['MonthlyIncome']].fillna(0)\n",
    "df_test[['NumberOfDependents']] = df_test[['NumberOfDependents']].fillna(0)\n",
    "df_test[['MonthlyIncome']] = df_test[['MonthlyIncome']].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # On vérifie la suppression\n",
    "# df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On ajoute une colonne NumberOfTimeGlobal égale à la somme des 3 autres colonnes NumberofTime\n",
    "df['NumberOfTimeGlobal'] = df['NumberOfTime30-59DaysPastDueNotWorse'] + df['NumberOfTime60-89DaysPastDueNotWorse']*2 + df['NumberOfTimes90DaysLate']*3\n",
    "df_test['NumberOfTimeGlobal'] = df_test['NumberOfTime30-59DaysPastDueNotWorse'] + df_test['NumberOfTime60-89DaysPastDueNotWorse']*2 + df_test['NumberOfTimes90DaysLate']*3\n",
    "\n",
    "df.drop(['NumberOfTime30-59DaysPastDueNotWorse', 'NumberOfTime60-89DaysPastDueNotWorse', 'NumberOfTimes90DaysLate'], axis=1)\n",
    "df_test.drop(['NumberOfTime30-59DaysPastDueNotWorse', 'NumberOfTime60-89DaysPastDueNotWorse', 'NumberOfTimes90DaysLate'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On insère une colonne is Old\n",
    "df.insert( 3, 'IsOld', 0)\n",
    "df_test.insert( 3, 'IsOld', 0)\n",
    "df.loc[df['age'] >= 70,'IsOld'] = 1\n",
    "df_test.loc[df_test['age'] >= 70,'IsOld'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On remplace les valeurs aberrante par la valeur mediane\n",
    "df.loc[df['NumberOfTime30-59DaysPastDueNotWorse'] >= 20,'NumberOfTime30-59DaysPastDueNotWorse'] = df['NumberOfTime30-59DaysPastDueNotWorse'].median()\n",
    "df.loc[df['NumberOfTime60-89DaysPastDueNotWorse'] >= 20,'NumberOfTime60-89DaysPastDueNotWorse'] = df['NumberOfTime60-89DaysPastDueNotWorse'].median()\n",
    "df.loc[df['NumberOfTimes90DaysLate'] >= 20,'NumberOfTimes90DaysLate'] = df['NumberOfTimes90DaysLate'].median()\n",
    "\n",
    "df_test.loc[df['NumberOfTime30-59DaysPastDueNotWorse'] >= 20,'NumberOfTime30-59DaysPastDueNotWorse'] = df_test['NumberOfTime30-59DaysPastDueNotWorse'].median()\n",
    "df_test.loc[df['NumberOfTime60-89DaysPastDueNotWorse'] >= 20,'NumberOfTime60-89DaysPastDueNotWorse'] = df_test['NumberOfTime60-89DaysPastDueNotWorse'].median()\n",
    "df_test.loc[df['NumberOfTimes90DaysLate'] >= 20,'NumberOfTimes90DaysLate'] = df_test['NumberOfTimes90DaysLate'].median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On renomme la première colonne en Id\n",
    "df.rename(columns={'Unnamed: 0': 'Id'}, inplace=True)\n",
    "df_test.rename(columns={'Unnamed: 0': 'Id'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On exporte en csv\n",
    "df.to_csv('storage/source_dataset_train_full.csv', index=False)\n",
    "df_test.to_csv('storage/source_dataset_test.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FIN DES PRETRAITEMENTS"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
